# Backend Onboarding Guide üöÄ

This document describes the process for setting up, developing, and deploying the backend for the "InnerJourney" project.

The backend is built with a modern tech stack:

-   üêç `FastAPI` (Python) for the API framework.
-   üî• `Firestore` (Firebase) for NoSQL data storage.
-   üîë Google Cloud `Secret Manager` for secure handling of API keys and sensitive data.
-   üê≥ `Docker` for containerization of the application.
-   ‚òÅÔ∏è `Google Cloud Run` for serverless deployment.

## Local Environment üíª

Setting up a working local environment is the first step to contributing to backend development.

### Install Required Tools üõ†Ô∏è

Ensure you have the following tools installed on your development machine:

-   üêç **`Python 3.10`**: Install this specific version to ensure compatibility with the project's dependencies.
-   üì¶ **`Virtualenv`**: Used to create an isolated virtual environment for the project's Python packages.

    ```bash title="Create and activate virtual environment"
    # Create virtual environment (in project root folder)
    python3.10 -m venv venv

    # Activate the environment (Linux/macOS)
    source venv/bin/activate

    # Activate the environment (Windows - Git Bash/WSL)
    # source venv/Scripts/activate
    # Activate the environment (Windows - Cmd/PowerShell)
    # venv\Scripts\activate
    ```

-   üêô **`Git`**: Required for version control and cloning the project.
-   üê≥ **`Docker`**: Necessary for building and running the application in a container, mirroring the production environment.
-   ‚òÅÔ∏è **`Google Cloud SDK (gcloud)`**: Used to interact with Google Cloud services from the command line, e.g., for deployment and authentication against Artifact Registry.

### Clone the Project from GitHub üì•

Clone the `InnerJourney` repository to your local machine:

```bash
git clone git@github.com:joelkvarnsmyr/InnerJourney.git
cd InnerJourney
```

### Install Project Dependencies üìú

With the virtual environment activated (`venv`), install all Python packages defined in `requirements.txt`:

```bash
pip install -r requirements.txt
```

### Configure Local Environment Variables üîë

To run the backend locally, you need to configure sensitive information. Create a file named `.env` in the project's root directory (`InnerJourney/`) and add the following variables:

```text title=".env file"
GEMINI_API_KEY="your-gemini-api-key"
FIREBASE_CREDENTIALS_PATH="~/.secrets/api-keys.json"
# Add any other local environment variables here
```

‚ö†Ô∏è **Important:**

*   Replace `"your-gemini-api-key"` with your actual Gemini API key.
*   Place your Firebase service account JSON file (named `api-keys.json` in the example) in the absolute path you specified in `FIREBASE_CREDENTIALS_PATH`.
*   The `.env` file and your service account file (`api-keys.json` in the example) should **never** be checked into Git. Ensure they (or the path to them) are included in the `.gitignore` file.

### Start the Server Locally ‚ñ∂Ô∏è

Start the `FastAPI` development server using `Uvicorn`. The command should be run from the project's root folder with the virtual environment activated:

```bash
uvicorn backend.main:app --host 0.0.0.0 --port 8080 --reload
```

Explanation of flags:
*   `--host 0.0.0.0`: Makes the server accessible from your local network (not just `localhost`).
*   `--port 8080`: The default port, also used in the Cloud Run configuration.
*   `--reload`: Restarts the server automatically when code changes are detected.

The server is now available at `http://localhost:8080`. You can open the API documentation (generated by FastAPI) in your browser at `http://localhost:8080/docs`.

You can also test a specific endpoint locally using `curl` or an API tool like Postman/Insomnia:

```bash title="Example call with curl"
# Example: Call /gemini/getActivation
curl -X POST "http://localhost:8080/gemini/getActivation" \
-H "Content-Type: application/json" \
-d '{"mood": 2, "goal": "get started"}'
```

## Git and Version Control üêô

Follow these guidelines to keep the codebase organized and facilitate collaboration:

-   üîó **Git repository:** The source code is managed on GitHub: `git@github.com:joelkvarnsmyr/InnerJourney.git`.
-   üå± **Branching Strategy:**
    *   The `main` branch represents the stable code that is deployed or ready for deployment. Direct commits to `main` are not allowed.
    *   Create `feature-branches` for all new work (new features, bug fixes, refactoring). Name them descriptively, e.g., `feature/new-user-profile`, `fix/login-error`.
    *   When a feature is complete, create a Pull Request (PR) against `main`. The PR should be reviewed by at least one other team member before being merged.
-   üí¨ **Commit Practices:**
    *   Commit often and in small, logical steps.
    *   Write clear and descriptive commit messages. Preferably follow the [Conventional Commits](https://www.conventionalcommits.org/) standard:
        *   `feat: Add password reset endpoint`
        *   `fix: Correct Firestore query logic in user service`
        *   `docs: Update backend onboarding guide with Docker details`
        *   `refactor: Improve error handling in gemini service`
        *   `ci: Add linting step to GitHub Actions workflow`
-   üö´ **Ignoring Sensitive Files:** Ensure the `.gitignore` file includes all files and folders that should not be version-controlled. This includes:
    *   Local configuration files: `.env`
    *   Virtual environments: `venv/`
    *   Python cache files: `__pycache__/`, `*.pyc`
    *   Local secrets/credentials: The path you use for `FIREBASE_CREDENTIALS_PATH` (e.g., `~/.secrets/`, `*.json` if it's in the project ‚Äì which is not recommended).
    *   IDE-specific folders: `.vscode/`, `.idea/`

## Firebase Integration üî•

The backend uses Firebase for several core functions:

-   üíæ **`Firestore`:** Used as the primary NoSQL database. Data stored here includes:
    *   User profiles
    *   Generated "activations" (`activations`)
    *   Application logs and other relevant data.
    *   (Potentially see a separate document `DatabaseStructure.md` for a detailed description of the data models).
-   üîë **`Firebase Admin SDK`:** The backend interacts with Firebase services (primarily `Firestore`) via the `Firebase Admin SDK` for Python. The SDK initialization is handled securely depending on the environment:
    *   **Production (Cloud Run):** Service account credentials are fetched dynamically from Google Cloud `Secret Manager`. This avoids having sensitive files in the codebase or container.
    *   **Local:** The path to the locally saved service account JSON file is read from the `FIREBASE_CREDENTIALS_PATH` environment variable in the `.env` file.
-   üíª **Code Example (`firebase_service.py`):** Below is a simplified excerpt from `firebase_service.py` illustrating how secrets are fetched from Secret Manager and how the Firebase Admin SDK is initialized when the application runs in Google Cloud.

    ```python title="firebase_service.py (Excerpt - Initialization & Save)"
    import firebase_admin
    from firebase_admin import credentials, firestore
    from google.cloud import secretmanager
    import json
    import os
    import logging

    # Configure basic logging
    logging.basicConfig(level=logging.INFO)

    # Initialize db as None globally
    db = None

    def get_secret(secret_id, project_id="innerjourney-c007e", version_id="latest"):
        """Fetches a secret from Google Secret Manager."""
        try:
            client = secretmanager.SecretManagerServiceClient()
            name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
            response = client.access_secret_version(request={"name": name})
            payload = response.payload.data.decode("UTF-8")
            logging.info(f"üîë Secret '{secret_id}' fetched from Secret Manager.")
            return payload
        except Exception as e:
            logging.error(f"‚ùå Error fetching secret '{secret_id}': {e}")
            return None

    def initialize_firebase():
        """Initializes the Firebase Admin SDK."""
        global db
        if firebase_admin._apps:
            logging.info("Firebase Admin SDK already initialized.")
            if db is None: # Ensure db is set if SDK is already initialized
                 db = firestore.client()
            return

        try:
            # Try fetching from Secret Manager (Production/Cloud Run)
            firebase_credentials_json = get_secret("firebase-credentials")
            if firebase_credentials_json:
                firebase_credentials_dict = json.loads(firebase_credentials_json)
                cred = credentials.Certificate(firebase_credentials_dict)
                firebase_admin.initialize_app(cred)
                db = firestore.client()
                logging.info("‚úÖ Firebase Admin SDK initialized successfully via Secret Manager.")
            else:
                # Fallback to local file via environment variable (Local development)
                local_creds_path = os.getenv("FIREBASE_CREDENTIALS_PATH")
                if local_creds_path:
                    expanded_path = os.path.expanduser(local_creds_path) # Handles '~'
                    if os.path.exists(expanded_path):
                        cred = credentials.Certificate(expanded_path)
                        firebase_admin.initialize_app(cred)
                        db = firestore.client()
                        logging.info(f"‚úÖ Firebase Admin SDK initialized successfully via local file: {expanded_path}")
                    else:
                        logging.error(f"‚ùå Local Firebase credentials file not found at: {expanded_path}")
                else:
                    logging.error("‚ùå No Firebase credentials source (Secret Manager or local file) could be found.")

        except json.JSONDecodeError as e:
            logging.error(f"‚ùå Error parsing Firebase credentials JSON from Secret Manager: {e}")
        except Exception as e:
            logging.error(f"‚ùå Unknown error initializing Firebase Admin SDK: {e}")

    # Call initialization on module import
    initialize_firebase()

    def save_to_firestore(collection: str, doc_id: str, data: dict):
        """Saves data to a specific Firestore collection."""
        if db:  # Check that db is initialized
            try:
                doc_ref = db.collection(collection).document(doc_id)
                doc_ref.set(data)
                logging.info(f"üíæ Data saved to Firestore: {collection}/{doc_id}")
                return True
            except Exception as e:
                logging.error(f"‚ùå Error saving to Firestore ({collection}/{doc_id}): {e}")
                return False
        else:
            logging.error("‚ùå Firestore client (db) is not initialized. Cannot save data.")
            return False
    ```

## Deployment to Google Cloud Run ‚òÅÔ∏è

The backend application is deployed as a containerized service to Google Cloud Run.

### Prerequisites ‚úÖ

Before you can deploy, ensure the following:

-   üèóÔ∏è **Google Cloud Project:** You need access to the GCP project `innerjourney-c007e` with sufficient permissions (e.g., `Cloud Run Admin`, `Service Account User`, `Storage Admin` for Artifact Registry).
-   üîå **Enabled APIs:** The following Google Cloud APIs must be enabled in the project:
    -   `Cloud Run API`
    -   `Secret Manager API`
    -   `Artifact Registry API` (used to store Docker images)
    -   `Cloud Build API` (if you plan to use Cloud Build for CI/CD)
    -   `Identity and Access Management (IAM) API`

### Build and Push Docker Image üê≥

The application is packaged into a Docker container using the `Dockerfile`.

-   üìÑ **`Dockerfile`:** The definition for how the container image should be built.

    ```dockerfile title="Dockerfile"
    # Use an official Python 3.10 slim image as base
    FROM python:3.10-slim

    # Set the working directory inside the container
    WORKDIR /app

    # Install system dependencies if necessary (e.g., for certain Python packages)
    # RUN apt-get update && apt-get install -y --no-install-recommends gcc && rm -rf /var/lib/apt/lists/*

    # Copy only requirements.txt first to leverage Docker layer caching
    COPY requirements.txt .

    # Update pip and install Python dependencies
    # Use --no-cache-dir to keep the image smaller
    RUN pip install --no-cache-dir --upgrade pip && \
        pip install --no-cache-dir -r requirements.txt

    # Copy the rest of the application code to the working directory
    COPY . .

    # Expose the port Uvicorn will listen on (Cloud Run sets $PORT)
    EXPOSE 8080

    # Command to start the application when the container runs
    # Listen on 0.0.0.0 and the port specified by Cloud Run ($PORT, default 8080)
    CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8080"]
    ```

-   üèóÔ∏è‚û°Ô∏è‚òÅÔ∏è **Build and push the image to Artifact Registry:** Use `gcloud` and `docker` to build and upload the image. Replace `europe-west1` with your region if it's different, and `innerjourney-repo` with the name of your Artifact Registry repository.

    1.  **Configure Docker:** Authenticate against Artifact Registry in your region (replace `europe-west1` if needed).
        ```bash
        gcloud auth configure-docker europe-west1-docker.pkg.dev
        ```
    2.  **Build the Docker image:** Run from the project's root folder where the `Dockerfile` is located. Tag the image with the format: `REGION-docker.pkg.dev/PROJECT-ID/REPO-NAME/IMAGE-NAME:TAG`.
        ```bash
        # Example:
        docker build -t europe-west1-docker.pkg.dev/innerjourney-c007e/innerjourney-repo/innerjourney-backend:latest .
        ```
    3.  **Push the image:** Upload the built image to Artifact Registry.
        ```bash
        docker push europe-west1-docker.pkg.dev/innerjourney-c007e/innerjourney-repo/innerjourney-backend:latest
        ```
    ‚ú® *Note: Ensure the Artifact Registry repository (`innerjourney-repo` in the example) exists in your GCP project and region.*

### Deploy to Cloud Run üöÄ

Use `gcloud` to deploy the newly pushed Docker image as a Cloud Run service.

-   ‚å®Ô∏è **Deploy command:**

    ```bash
    # Replace [SERVICE_ACCOUNT_EMAIL] with the service account email address
    gcloud run deploy innerjourney-backend \
      --image europe-west1-docker.pkg.dev/innerjourney-c007e/innerjourney-repo/innerjourney-backend:latest \
      --platform managed \
      --region europe-west1 \
      --service-account=[SERVICE_ACCOUNT_EMAIL] \
      --allow-unauthenticated \
      # Add any environment variables that are NOT secrets here
      # For example: --set-env-vars=LOG_LEVEL=INFO
      # Secrets are mounted separately (see next section)
    ```
    *   **Service Account (`--service-account`):** Specify the email address of the **specific service account** that the Cloud Run service should run as. This account needs carefully configured IAM permissions to access other GCP services (like Secret Manager, Firestore, etc.). Avoid using the broader default Compute Engine service account if possible.
    *   ‚ö†Ô∏è **Warning (`--allow-unauthenticated`):** This flag makes your service publicly accessible on the internet without requiring authentication. For most production applications, you should **remove** this flag and implement authentication/authorization, e.g., via Google Cloud IAM, Identity Platform, Firebase Auth, or an API Gateway in front of the service.

-   üîó **Service URL:** After a successful deployment, `gcloud` will print the public URL for your service, e.g., `https://innerjourney-backend-xxxxxxxxxx-ew.a.run.app`.

### Manage Secrets in Cloud Run üîí

Sensitive data like API keys and database credentials should **never** be baked into the Docker image or set as regular environment variables. Use Google Cloud `Secret Manager` instead.

-   üîë **Stored Secrets:** The primary secrets the backend needs are stored in Secret Manager under the following names (secrets):
    -   `firebase-credentials`: Contains the entire content of the Firebase service account JSON file as a text string.
    -   `gemini-api-key`: Contains the API key for Gemini.
-   ‚öôÔ∏è **Mount Secrets in Cloud Run:** When deploying (or updating) your Cloud Run service, you can configure it to mount secrets as environment variables or as files in the container's filesystem. Mounting as environment variables is often the simplest:

    ```bash title="Example: Mount secrets as environment variables"
    # Example of mounting secrets as environment variables during deployment
    gcloud run deploy innerjourney-backend \
      --image ... \
      --region ... \
      --service-account ... \
      # Remove --allow-unauthenticated if authentication is required
      # Mount firebase-credentials as environment variable FIREBASE_CREDENTIALS_JSON
      --update-secrets=FIREBASE_CREDENTIALS_JSON=firebase-credentials:latest \
      # Mount gemini-api-key as environment variable GEMINI_API_KEY
      --update-secrets=GEMINI_API_KEY=gemini-api-key:latest
      # ... other flags ...
    ```
    The application code (as in the `firebase_service.py` example above) can then read these environment variables.

-   üõ°Ô∏è **Permissions for the Service Account:** The service account specified in `--service-account` **must** have the IAM role `Secret Manager Secret Accessor` to be allowed to read the values from Secret Manager. Configure this in the GCP Console:
    1.  Navigate to `IAM & Admin` -> `IAM`.
    2.  Find the email address of the service account used by the Cloud Run service.
    3.  Click the pencil icon (Edit principal) for that account.
    4.  Click `+ ADD ANOTHER ROLE`.
    5.  Search for and select the role `Secret Manager Secret Accessor`.
    6.  Click `SAVE`.

## Troubleshooting and Common Issues üêû

Here are solutions to some common problems that might occur during development or deployment.

### `404 Not Found` When Calling an Endpoint

-   ü§î **Cause:** `FastAPI` cannot find the specific route (URL path) you are trying to call, e.g., `/gemini/getActivation` or `/users/profile`. This usually happens because the router for the specific functionality (e.g., `gemini_router`, `users_router`) has not been correctly imported and included in the main application object in `backend/main.py`.
-   ‚úÖ **Solution:**
    1.  Open the file `backend/main.py`.
    2.  Verify that the router for the missing endpoint is imported at the top (e.g., `from .routers import gemini, users`).
    3.  Check that `app.include_router()` is called for the router, with the correct `prefix` and `tags`. Example:
        ```python title="backend/main.py (Router Inclusion)"
        # ... imports ...
        from .routers import gemini, users # Make sure your router is here

        app = FastAPI(title="InnerJourney Backend")

        # ... middleware etc. ...

        # Include routers
        app.include_router(gemini.router, prefix="/gemini", tags=["Gemini"])
        app.include_router(users.router, prefix="/users", tags=["Users"])
        # ... include other routers ...
        ```
    4.  Double-check the spelling of the prefix (e.g., `/gemini`) and the endpoint definition in the router file itself (e.g., `@router.post("/getActivation", ...)`).

### `PermissionDenied` When Accessing Secret Manager or Firestore

-   ü§î **Cause:** This almost always occurs when the Cloud Run service is running. The error means that the service account the service runs as (`--service-account`) lacks the necessary IAM permissions to access the specific GCP service (Secret Manager or Firestore/Datastore). The error is clearly visible in the Cloud Run service's logs in the GCP Console.
    *   For Secret Manager, the most common missing permission is `secretmanager.versions.access` (included in the `Secret Manager Secret Accessor` role).
    *   For Firestore, roles like `Cloud Datastore User` or more specific Firestore roles are required.
-   ‚úÖ **Solution:**
    1.  Identify the exact service account your Cloud Run service is using. You can use `gcloud` or check in the GCP Console:
        ```bash
        gcloud run services describe innerjourney-backend --region=europe-west1 --format='value(spec.template.spec.serviceAccountName)'
        ```
    2.  Go to `IAM & Admin` > `IAM` in the Google Cloud Console.
    3.  Find the service account in the list of principals.
    4.  Click the edit pencil (Edit principal).
    5.  **Add** the necessary roles:
        *   For Secret Manager: Add the role `Secret Manager Secret Accessor`.
        *   For Firestore: Add the role `Cloud Datastore User` (provides broad access) or a more limited role if possible.
    6.  Click `SAVE`.
    7.  A new deployment of the Cloud Run service might be required for the changes to be picked up immediately (`gcloud run deploy ...` with the same image).

### Container Failed to Start / Application Error

-   ü§î **Cause:** The application crashes immediately when the container attempts to start in Cloud Run. This can have many causes:
    *   **Syntax Error:** An error in the Python code prevents it from even loading.
    *   **Missing Dependencies:** A package used in the code is not specified in `requirements.txt` or failed to install during `docker build`.
    *   **Configuration Error:** Problems reading environment variables, initializing the Firebase SDK (e.g., invalid credentials, incorrect path), or other startup configurations.
    *   **Port Issues:** The `Uvicorn` command in the `Dockerfile` (`CMD`) is incorrect or tries to bind to the wrong port (Cloud Run expects the app to listen on the port specified in the `$PORT` environment variable, which is often `8080`).
    *   **Import Error:** Problems with relative or absolute imports in the Python code.
-   ‚úÖ **Solution:**
    1.  **Check the Logs:** üîç This is the most important step. Go to your Cloud Run service in the GCP Console and select the `LOGS` tab. Review the logs (especially those marked as Error) carefully. They usually contain a Python traceback or an error message pointing to the exact cause of the crash.
    2.  **Test Locally with Docker:** üíª Build and run the exact same Docker image locally to troubleshoot in a controlled environment. This helps isolate whether the problem lies in the code/container or the Cloud Run configuration.
        ```bash title="Run container locally for troubleshooting"
        # 1. Build the image locally (if you haven't already)
        docker build -t innerjourney-backend-local .

        # 2. Run the container locally, map port 8080, and pass environment variables
        # Use --env-file to read from your local .env file:
        # docker run --rm -p 8080:8080 --env-file .env innerjourney-backend-local

        # Alternatively, set variables manually (adjust values):
        docker run --rm -p 8080:8080 \
          -e PORT=8080 \
          -e FIREBASE_CREDENTIALS_PATH="/app/path/to/your/local-or-mock-credentials.json" \
          -e GEMINI_API_KEY="your-local-key" \
          innerjourney-backend-local
        ```
        See if the container starts and if you get any error messages in the terminal.
    3.  **Verify `Dockerfile` and `requirements.txt`:** ‚ú® Double-check that all necessary packages are listed in `requirements.txt`. Ensure the `Dockerfile` correctly copies all necessary code (`COPY . .`) *after* `pip install` and that the `CMD` instruction is correct (`uvicorn backend.main:app --host 0.0.0.0 --port 8080`).